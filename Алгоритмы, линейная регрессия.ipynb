{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "65062b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=100000, n_features=14, n_informative=10, noise=15, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c2bd5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLineReg:    \n",
    "    \"\"\"\n",
    "    Линейная регрессия\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_iter : int, optional\n",
    "        Количество шагов градиентного спуска, by default 100\n",
    "    learning_rate : float, optional\n",
    "        Коэффициент скорости обучения градиентного спуска.\n",
    "        Если на вход пришла lambda-функция, то learning_rate вычисляется на каждом шаге на основе переданной функцией\n",
    "    weights : np.ndarray, optional\n",
    "        Веса модели\n",
    "    metric : str, optional\n",
    "        Метрика, которая будет вычисляться параллельно с функцией потерь.\n",
    "        Принимает одно из следующих значений: mae, mse, rmse, mape, r2\n",
    "    reg : str, optional\n",
    "        Вид регуляризации. Принимает одно из следующих значений: l1, l2, elasticnet, by default None\n",
    "    l1_coef : float, optional\n",
    "        Коэффициент L1 регуляризации. Принимает значения от 0.0 до 1.0, by default 0\n",
    "    l2_coef : float, optional\n",
    "        Коэффициент L2 регуляризации. Принимает значения от 0.0 до 1.0, by default 0\n",
    "    sgd_sample : Union[int, float], optional\n",
    "        Количество образцов, которое будет использоваться на каждой итерации обучения.\n",
    "        Может принимать целые числа, либо дробные от 0.0 до 1.0, by default None\n",
    "    random_state : int, optional\n",
    "        Сид для воспроизводимости результата, by default 42\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_iter: int = 100, \n",
    "                 learning_rate: float = 0.1,             \n",
    "                 metric: str | None = None, \n",
    "                 reg: str | None = None, \n",
    "                 l1_coef: float = 0.0, \n",
    "                 l2_coef: float = 0.0, \n",
    "                 random_state: int = 42, \n",
    "                 sgd_sample: str | None = None) -> None:\n",
    "                \n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = None\n",
    "        self.metric = metric\n",
    "        self.best_score = None\n",
    "        self.metrics = {\n",
    "            'mae':  lambda y, y_pred: np.mean(np.abs(y - y_pred)),\n",
    "            'mse':  lambda y, y_pred: np.mean((y - y_pred) ** 2),\n",
    "            'rmse': lambda y, y_pred: np.sqrt(np.mean((y - y_pred) ** 2)),\n",
    "            'mape': lambda y, y_pred: np.mean(np.abs((y - y_pred) / y)) * 100,\n",
    "            'r2':   lambda y, y_pred: 1 - np.sum((y - y_pred) ** 2) / np.sum((y - np.mean(y)) ** 2)\n",
    "        }\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.sgd_sample = sgd_sample \n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int | bool = False) -> None:        \n",
    "        \"\"\"Обучение линейной регрессии\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Все фичи\n",
    "        y : pd.Series\n",
    "            Целевая переменная\n",
    "        verbose : int, optional\n",
    "            Указывает через сколько итераций градиентного спуска будет выводиться лог\n",
    "        \"\"\"\n",
    "        \n",
    "        random.seed(self.random_state)\n",
    "        n_samples, n_features = X.shape\n",
    "        X = X.copy()\n",
    "        ones = np.ones(n_samples)\n",
    "        X.insert(0, 'x_0', ones)\n",
    "        \n",
    "        self.weights = np.ones(n_features + 1)\n",
    "\n",
    "        for iter in range(self.n_iter):\n",
    "            \n",
    "            if isinstance(self.sgd_sample, float):\n",
    "                sample_rows_idx = random.sample(range(X.shape[0]), round(X.shape[0] * self.sgd_sample))                \n",
    "            if isinstance(self.sgd_sample, int):\n",
    "                sample_rows_idx = random.sample(range(X.shape[0]), self.sgd_sample)            \n",
    "            if not self.sgd_sample:\n",
    "                sample_rows_idx = range(X.shape[0])                                                \n",
    "            X_batch = X.iloc[sample_rows_idx]\n",
    "            y_batch = y.iloc[sample_rows_idx]\n",
    "            \n",
    "            y_pred = X @ self.weights\n",
    "            loss = np.sum((y - y_pred) ** 2) / n_samples            \n",
    "            \n",
    "            if self.reg == 'l1' or self.reg == 'elasticnet':\n",
    "                loss += self.l1_coef * np.sum(np.abs(self.weights))\n",
    "            if self.reg == 'l2' or self.reg == 'elasticnet':\n",
    "                loss += self.l2_coef * np.sum(self.weights ** 2)\n",
    "                \n",
    "            if not isinstance(self.learning_rate, (float, int)):\n",
    "                lr = self.learning_rate(iter + 1)\n",
    "                self.weights -= lr * self.__calc_grad(X_batch, y_batch)\n",
    "            else:\n",
    "                self.weights -= self.learning_rate * self.__calc_grad(X_batch, y_batch)\n",
    "\n",
    "            if self.metric:\n",
    "                self.best_score = self.metrics[self.metric](y, y_pred)\n",
    "\n",
    "            if verbose and iter % verbose == 0:\n",
    "                print(f\"{iter if iter != 0 else 'start'} | loss: {loss}\", f\"| {self.metric}: {self.best_score}\" if self.metric else '')\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Выдача предсказаний моделью\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Матрица фичей\n",
    "        \"\"\"\n",
    "        \n",
    "        X = X.copy()\n",
    "        ones = np.ones(X.shape[0])\n",
    "        X.insert(0, 'x_0', ones)\n",
    "        return X @ self.weights\n",
    "    \n",
    "    def __calc_grad(self, X: pd.DataFrame, y: pd.Series) -> float:\n",
    "        n_samples, _ = X.shape\n",
    "        grad = 2 / n_samples * (X.T @ (X @ self.weights - y))\n",
    "        \n",
    "        if self.reg:\n",
    "            if self.reg == 'l1' or self.reg == 'elasticnet':\n",
    "                grad += self.l1_coef * np.sign(self.weights)\n",
    "            if self.reg == 'l2' or self.reg == 'elasticnet':\n",
    "                grad += self.l2_coef * 2 * self.weights\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    def get_coef(self) -> pd.Series:\n",
    "        return self.weights[1:]\n",
    "\n",
    "    def get_best_score(self) -> float:\n",
    "        return self.best_score\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\" + \\\n",
    "            f' metric={self.metric}, reg={self.reg}, sgd_sample={self.sgd_sample}'\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'MyLineReg class: {self.__dict__}'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2954f1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226.73336547132743"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LineReg = MyLineReg(n_iter = 100, \n",
    "              learning_rate = lambda iter: 0.7 * (0.9 ** iter), \n",
    "              metric = 'mse', \n",
    "              reg = 'l1', \n",
    "              l1_coef = 0.1, \n",
    "              l2_coef = 0.0)\n",
    "\n",
    "LineReg.fit(X_train, y_train)\n",
    "y_pred = LineReg.predict(X_test)\n",
    "LineReg.get_best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "36024e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223.41974177996778"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = LinearRegression().fit(X_train, y_train).predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5485a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
